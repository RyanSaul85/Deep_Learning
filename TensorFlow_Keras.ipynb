{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow and Keras Lesson"
      ],
      "metadata": {
        "id": "1DWTMox4-y9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6ltnXPJQhQ1",
        "outputId": "e345942c-d571-4497-b79f-1d527a9e6e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.21.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.37.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.47.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "# CPU TensorFlow\n",
        "# !pip install tensorflow==2.0.0-rc1\n",
        "\n",
        "# GPU TensorFlow\n",
        "!pip install tensorflow-gpu==2.0.0\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "build your ANN step by step, using the Sequential() class\n",
        "\n",
        "When implementing an ANN in Keras, you'll use the following steps:\n",
        "- Create a model object.\n",
        "- Add layers to the model one by one.\n",
        "\n",
        "After doing these steps, you'll end up with a deep-learning model structure. The next steps are as follows:\n",
        "- Define an optimizer and compile the model.\n",
        "- After compiling the model, train the model using training data.\n",
        "- Evaluate the performance of the model on a test set."
      ],
      "metadata": {
        "id": "sFy_RWblYy2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import Sequential Class from Keras\n",
        " - from tensorflow.keras.models import Sequential\n",
        "2. Create model object\n",
        " - model = Sequential()\n",
        "3. Compile the model\n",
        " - model.compile(optimizer, loss, metrics)\n",
        "4. Add layers to the model\n",
        " - model.add(Dense())\n",
        "5. Train the model\n",
        " - model.fit(X_train, Y_train)\n",
        "6. Evaluate the model\n",
        " - model.evaluate(X_test, Y_test)"
      ],
      "metadata": {
        "id": "YSdMXKMTZTJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "sVJyhikNX0s0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data and do preprocessing"
      ],
      "metadata": {
        "id": "fHAJu1I0alEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PEMiMgcad8h",
        "outputId": "bb738881-6f2d-4000-bdda-ee349be2b402"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, one-hot code your target variable using the to_categorical() function from the keras.utils module:"
      ],
      "metadata": {
        "id": "Xtm-sHKTayTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "metadata": {
        "id": "SsUjKL-KanMb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the size"
      ],
      "metadata": {
        "id": "nEBG8gYrbSuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOIOepQJa4Tb",
        "outputId": "36b3b5da-e815-40bc-a123-c9225a5e9dcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot some images"
      ],
      "metadata": {
        "id": "yTZo6IuYbZY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(141)\n",
        "plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
        "\n",
        "plt.subplot(143)\n",
        "plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
        "\n",
        "plt.subplot(144)\n",
        "plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "aB_pQnbWbU2K",
        "outputId": "f1f0f88c-7243-4aaa-e43f-4dff99bcd171"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model - Sequential"
      ],
      "metadata": {
        "id": "wYnTLA_JbwsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# The first dense layer\n",
        "model.add(Dense(1028, input_shape=(784,), activation=\"relu\"))\n",
        "# The second dense layer\n",
        "model.add(Dense(1028, activation=\"relu\"))\n",
        "# The last layer is the output layer\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "kQTdBe2Rbbw2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzx0RfqRb3Nf",
        "outputId": "f42bf834-157a-4941-9588-2243c6f9307c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1028)              806980    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10290     \n",
            "=================================================================\n",
            "Total params: 1,875,082\n",
            "Trainable params: 1,875,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model\n",
        "1. The optimizer that will be used in the training: If you don't know about optimizers in deep learning, don't worry. You just need to use one in this lesson, and you'll learn about optimizers later in this module.\n",
        "2. The loss function: It's necessary to specify a loss function for a model. Training algorithms use this loss function and try to minimize it during the training. This will also be covered in the next lesson.\n",
        "3. The metric to measure the training performance of your model: In this example, you use the accuracy metric, because your task is a classification task and your dataset is a balanced one."
      ],
      "metadata": {
        "id": "sFdjiRthcHGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "usuIVNb1cAYA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model\n",
        "- Use 128 as the batch size. Batch size is something that you'll explore in a later lesson.\n",
        "- Use 20 as the number of epochs. In deep-learning jargon, epoch means full use of all of the examples in the training data during the training of the model."
      ],
      "metadata": {
        "id": "2Dmv_5q4cTI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE9hctURcRFW",
        "outputId": "f61c4029-3874-4ad0-ddbf-97c496d949d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 25s 415us/sample - loss: 1.0429 - accuracy: 0.7816\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 19s 309us/sample - loss: 0.4243 - accuracy: 0.8923\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 18s 305us/sample - loss: 0.3409 - accuracy: 0.9061\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 18s 299us/sample - loss: 0.3028 - accuracy: 0.9157\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 18s 301us/sample - loss: 0.2777 - accuracy: 0.9225\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 19s 314us/sample - loss: 0.2586 - accuracy: 0.9275\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 18s 296us/sample - loss: 0.2431 - accuracy: 0.9323\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 18s 295us/sample - loss: 0.2297 - accuracy: 0.9354\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 18s 294us/sample - loss: 0.2181 - accuracy: 0.9384\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 18s 298us/sample - loss: 0.2078 - accuracy: 0.9413\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 18s 294us/sample - loss: 0.1984 - accuracy: 0.9445\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 18s 292us/sample - loss: 0.1896 - accuracy: 0.9471\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 17s 289us/sample - loss: 0.1816 - accuracy: 0.9490\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 18s 294us/sample - loss: 0.1743 - accuracy: 0.9507\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 18s 297us/sample - loss: 0.1675 - accuracy: 0.9529\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 18s 293us/sample - loss: 0.1614 - accuracy: 0.9549\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 18s 295us/sample - loss: 0.1554 - accuracy: 0.9568\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 18s 296us/sample - loss: 0.1499 - accuracy: 0.9577\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 18s 297us/sample - loss: 0.1445 - accuracy: 0.9599\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 17s 291us/sample - loss: 0.1397 - accuracy: 0.9607\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb83bb14450>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "t5Rn7hWacnIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikwxo_8qcfjp",
        "outputId": "c645961d-6817-4a75-d715-1609d0fdb084"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.14310873336195945\n",
            "Test accuracy: 0.9576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow and Keras Assignment"
      ],
      "metadata": {
        "id": "W_5jb8_X-pj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In this task, you'll build an ANN and train and test it using the MNIST data. This ANN should consist of two hidden layers and one output layer. All of the hidden layers should be dense. The first layer and the second layer should have neuron sizes of 32 and 16, respectively. Train this model for 20 epochs, and compare your training and test set performance with the example in the lesson. Is there any difference? If so, why?"
      ],
      "metadata": {
        "id": "Sd1R6y2CAkSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM6SlvEh_kui",
        "outputId": "6e6d357f-05cb-4839-fb1e-b193420e3d38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# our first dense layer is 32\n",
        "model.add(Dense(32, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer is 16\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "# last layer, the output layer, is 10\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "w8G8kvGScsbT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwjTj4BFAGb7",
        "outputId": "51faa173-c431-41c2-a2cb-41b8efce5240"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 25,818\n",
            "Trainable params: 25,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "TfRlLdMt_UlX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting `verbose=1` prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVx4DlLEAKS0",
        "outputId": "09cfcddc-a804-49e4-b967-929b41bfed68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 2s 33us/sample - loss: 1.4684 - accuracy: 0.5551\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.5988 - accuracy: 0.8411\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4360 - accuracy: 0.8792\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.3791 - accuracy: 0.8923\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3474 - accuracy: 0.9011\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.3250 - accuracy: 0.9074\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.3080 - accuracy: 0.9119\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2936 - accuracy: 0.9162\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2817 - accuracy: 0.9200\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2709 - accuracy: 0.9228\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2619 - accuracy: 0.9255\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2536 - accuracy: 0.9279\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2461 - accuracy: 0.9301\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2392 - accuracy: 0.9316\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2329 - accuracy: 0.9334\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2268 - accuracy: 0.9352\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2210 - accuracy: 0.9368\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2159 - accuracy: 0.9380\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2110 - accuracy: 0.9396\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2063 - accuracy: 0.9411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb892e0f750>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDzKB5s4ATDK",
        "outputId": "7c377e4c-7918-4f82-c8ca-b8ff971fe50e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.20925037734806537\n",
            "Test accuracy: 0.9404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lesson Results:\n",
        "- train score (loss) 0.1397\n",
        "- train accuracy 0.9607\n",
        "- test score: 0.1431\n",
        "- test accuracy: 0.9576\n",
        "\n",
        "Example Results:\n",
        "- train score (loss) 0.2063\n",
        "- train accuracy 0.9411\n",
        "- test score 0.2093\n",
        "- test accuracy 0.9404\n",
        "\n",
        "Both the train and test scores are pretty similar in both models. The first model had much more dense layers resulting in slightly better values for loss and accuracy."
      ],
      "metadata": {
        "id": "bQ5iuDWCAro7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. In this task, build another ANN. This ANN should have five hidden layers and one output layer. All of the layers should be dense. The neuron numbers for the hidden layers should be 1024, 512, 256, 128, and 64. Train this model for 20 epochs, and test it using the same data from the previous task. Then compare your results. Is there any difference? If so, why?"
      ],
      "metadata": {
        "id": "v6WahmjQBopy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# our first dense layer is 1024\n",
        "model.add(Dense(1024, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer is 512\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "# our third dense layer is 256\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "# our fourth dense layer is 128\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "# our fifth dense layer is 64\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "# last layer, output layer, is 10\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "p0OFsQy7Aa3T"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "U3q6CoW8CTxs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F4-m8wACX_W",
        "outputId": "add882ff-e2d9-40fc-afc1-14165720587c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 17s 276us/sample - loss: 1.2869 - accuracy: 0.6790\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 15s 253us/sample - loss: 0.3790 - accuracy: 0.8932\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 15s 254us/sample - loss: 0.2882 - accuracy: 0.9162\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 15s 252us/sample - loss: 0.2430 - accuracy: 0.9283\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.2103 - accuracy: 0.9386\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 15s 256us/sample - loss: 0.1871 - accuracy: 0.9456\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 15s 249us/sample - loss: 0.1659 - accuracy: 0.9516\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 15s 250us/sample - loss: 0.1505 - accuracy: 0.9559\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 16s 258us/sample - loss: 0.1358 - accuracy: 0.9607\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 15s 252us/sample - loss: 0.1238 - accuracy: 0.9645\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 15s 247us/sample - loss: 0.1136 - accuracy: 0.9672\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.1044 - accuracy: 0.9706\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 15s 246us/sample - loss: 0.0964 - accuracy: 0.9723\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 15s 253us/sample - loss: 0.0889 - accuracy: 0.9746\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 15s 250us/sample - loss: 0.0823 - accuracy: 0.9770\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 15s 247us/sample - loss: 0.0756 - accuracy: 0.9785\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0707 - accuracy: 0.9799\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 15s 253us/sample - loss: 0.0650 - accuracy: 0.9822\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.0605 - accuracy: 0.9833\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 15s 250us/sample - loss: 0.0561 - accuracy: 0.9848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb830594610>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdLpcWIkCaoJ",
        "outputId": "92d8f51c-e8d9-4250-99b7-1ea879b5a2bf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.08592790067396126\n",
            "Test accuracy: 0.9734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test score is 0.0859 and the test accuracy is 0.9734, which are both better values than the previous models. There are more layers and they are more dense, leading to better train and test results, but the runtime was much longer. The difference in the training and test score was much larger potentially resulting in a too complex model that may be overfitting."
      ],
      "metadata": {
        "id": "6e_NgBv1D2e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IHZILEISDx5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}